{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e-QvMSz-sEr"
      },
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EomaWHOr2jnQ",
        "outputId": "727f9de4-77bc-4648-ac49-b28434ae4b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLLYu7z06xJL",
        "outputId": "e72fbf92-5c5b-47c4-df89-896a154749ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting: drive/MyDrive/CULane/list.tar.gz to data/culane/list\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/laneseg_label_w16.tar.gz to data/culane/laneseg_label_w16\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/annotations_new.tar.gz to data/culane/annotations_new\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/training_validation/driver_182_30frame.tar.gz to data/culane/training_validation/driver_182_30frame\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/training_validation/driver_161_90frame.tar.gz to data/culane/training_validation/driver_161_90frame\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/training_validation/driver_23_30frame.tar.gz to data/culane/training_validation/driver_23_30frame\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/testing/driver_193_90frame.tar.gz to data/culane/testing/driver_193_90frame\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/testing/driver_100_30frame.tar.gz to data/culane/testing/driver_100_30frame\n",
            "\n",
            "Extracting: drive/MyDrive/CULane/testing/driver_37_30frame.tar.gz to data/culane/testing/driver_37_30frame\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "def extract_tar_files(src_dir, dest_dir):\n",
        "    # Create destination directory if it doesn't exist\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "\n",
        "    # Iterate through files in source directory\n",
        "    for root, dirs, files in os.walk(src_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.tar.gz'):\n",
        "                # Construct source and destination paths\n",
        "                src_path = os.path.join(root, file)\n",
        "                rel_path = os.path.relpath(src_path, src_dir)\n",
        "                dest_path = os.path.join(dest_dir, rel_path[:-7])  # Remove '.tar.gz' extension\n",
        "\n",
        "                # Create destination directory if it doesn't exist\n",
        "                os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "                # Extract the tar.gz file\n",
        "                print(\"Extracting:\", src_path, \"to\", dest_path)\n",
        "                with tarfile.open(src_path, 'r:gz') as tar:\n",
        "                    tar.extractall(path=dest_path)\n",
        "                print()  # Print a new line after extracting each tar file\n",
        "\n",
        "# Specify source and destination directories\n",
        "src_directory = 'drive/MyDrive/CULane'\n",
        "dest_directory = 'data/culane'\n",
        "\n",
        "# Extract tar.gz files recursively\n",
        "extract_tar_files(src_directory, dest_directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJyOcYb_-qzl"
      },
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvNp6iQCAiAV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQU_Vq4XG7D6"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert nonzero pixels to (255, 255, 255)\n",
        "    image[image != 0] = 255\n",
        "    return image\n",
        "\n",
        "def construct_dataframe(text_file_path, raw_image_dir, resulting_image_dir):\n",
        "    data = []\n",
        "    counter = 0\n",
        "    with open(text_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            counter += 1\n",
        "            if counter % 9999 != 0:\n",
        "                continue\n",
        "            # Split the line into components\n",
        "            components = line.strip().split()\n",
        "            raw_relative_path = components[0].strip()\n",
        "            first_directory = raw_relative_path.split('/')[1]\n",
        "            raw_image_path = raw_image_dir.strip() + '/' + first_directory + '/' + raw_relative_path\n",
        "            resulting_image_path = resulting_image_dir.strip() + '/' + components[1].strip()\n",
        "            bool_values = [bool(int(val)) for val in components[2:6]]\n",
        "\n",
        "            # Load raw and resulting images\n",
        "            raw_image = cv2.imread(raw_image_path)\n",
        "            raw_image = cv2.resize(raw_image, None, fx=.1, fy=.1)\n",
        "            resulting_image = cv2.imread(resulting_image_path)\n",
        "            resulting_image[resulting_image != 0] = 255\n",
        "            resulting_image = cv2.resize(resulting_image, None, fx=.1, fy=.1)\n",
        "\n",
        "            # Append to data list\n",
        "            data.append([raw_image, *bool_values, resulting_image])\n",
        "\n",
        "    # Construct DataFrame\n",
        "    df = pd.DataFrame(data, columns=['Raw_Image', 'Bool_1', 'Bool_2', 'Bool_3', 'Bool_4', 'Resulting_Image'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZGbdqlGfiO4"
      },
      "outputs": [],
      "source": [
        "train_text_file_path = 'data/culane/list/list/train_gt.txt'\n",
        "validation_text_file_path = 'data/culane/list/list/val_gt.txt'\n",
        "raw_image_dir = 'data/culane/training_validation'\n",
        "resulting_image_dir = 'data/culane/laneseg_label_w16'\n",
        "\n",
        "train_df = construct_dataframe(train_text_file_path, raw_image_dir, resulting_image_dir)\n",
        "validation_df = construct_dataframe(validation_text_file_path, raw_image_dir, resulting_image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygCjDF8Of-Ml"
      },
      "outputs": [],
      "source": [
        "def standard_metrics(y_true, y_pred):\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    return accuracy, precision, recall, f1, mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lYmcn6Bi9MP"
      },
      "outputs": [],
      "source": [
        "def flatten_split_dataframe(df):\n",
        "    # Extract features from image columns and reshape into appropriate format\n",
        "    X_image = df['Raw_Image']\n",
        "    y = df['Resulting_Image']  # Flatten the last column (image)\n",
        "    return X_image, y\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "def train(model, X_train, y_train, validation_df):\n",
        "    X_batches = np.array_split(X_train, len(X_train) // batch_size)\n",
        "    y_batches = np.array_split(y_train, len(y_train) // batch_size)\n",
        "    for X_batch, y_batch in zip(X_batches, y_batches):\n",
        "        # Fit the model to the training data\n",
        "        model.fit(X_batches, y_batches)\n",
        "\n",
        "        # Once the model is trained, you can use it to make predictions on new data\n",
        "        # Assuming X_val is your validation features\n",
        "        X_val, y_val = flatten_split_dataframe(validation_df)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(X_val)\n",
        "\n",
        "        # Evaluate predictions on validation set\n",
        "        accuracy_val, precision_val, recall_val, f1_val, mse_val = standard_metrics(predictions, y_val)\n",
        "        print(\"Linear Regression Metrics on Validation Set:\")\n",
        "        print(\"Accuracy:\", accuracy_val)\n",
        "        print(\"Precision:\", precision_val)\n",
        "        print(\"Recall:\", recall_val)\n",
        "        print(\"F1 Score:\", f1_val)\n",
        "        print(\"Mean Squared Error:\", mse_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "JnwsXPOlgCXG",
        "outputId": "a6e1edfd-792b-4463-dcab-ed7880eb1885"
      },
      "outputs": [],
      "source": [
        "# Assuming X_train and y_train are your training features and target respectively\n",
        "X_train, y_train = flatten_split_dataframe(train_df)\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "train(model, X_train, y_train, validation_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
